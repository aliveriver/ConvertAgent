"""
LangChain Agent æ ¸å¿ƒé€»è¾‘
è´Ÿè´£ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œç”Ÿæˆä»£ç å¤„ç†æ–‡æ¡£
"""
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from tools import get_document_tools
import json
from code_executor import get_code_execution_tools

class DocumentAgent:
    """æ–‡æ¡£å¤„ç† Agent - åŸºäºä»£ç ç”Ÿæˆ"""
    
    # API æä¾›å•†é…ç½®
    PROVIDERS = {
        "openai": {
            "name": "OpenAI",
            "base_url": "https://api.openai.com/v1",
            "models": ["gpt-4-turbo-preview", "gpt-4", "gpt-3.5-turbo"],
            "default_model": "gpt-4-turbo-preview"
        },
        "siliconflow": {
            "name": "ç¡…åŸºæµåŠ¨ SiliconFlow",
            "base_url": "https://api.siliconflow.cn/v1",
            "models": ["Pro/zai-org/GLM-4.7", "Qwen/Qwen2.5-72B-Instruct", "deepseek-ai/DeepSeek-V2.5"],
            "default_model": "Qwen/Qwen2.5-72B-Instruct"
        },
        "zhipu": {
            "name": "æ™ºè°±AI GLM",
            "base_url": "https://open.bigmodel.cn/api/paas/v4",
            "models": ["glm-4", "glm-4-plus", "glm-3-turbo"],
            "default_model": "glm-4"
        },
        "moonshot": {
            "name": "æœˆä¹‹æš—é¢ Kimi",
            "base_url": "https://api.moonshot.cn/v1",
            "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
            "default_model": "moonshot-v1-32k"
        },
        "deepseek": {
            "name": "DeepSeek",
            "base_url": "https://api.deepseek.com/v1",
            "models": ["deepseek-chat", "deepseek-coder"],
            "default_model": "deepseek-chat"
        }
    }
    
    def __init__(
        self, 
        api_key: str,
        provider: str = "openai",
        model_name: str = None
    ):
        """
        åˆå§‹åŒ– Agent
        
        Args:
            api_key: API å¯†é’¥
            provider: æä¾›å•† ID (openai/siliconflow/zhipu/moonshot/deepseek)
            model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
        """
        # è·å–æä¾›å•†é…ç½®
        if provider not in self.PROVIDERS:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
        
        provider_config = self.PROVIDERS[provider]
        
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        if model_name is None:
            model_name = provider_config["default_model"]
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0,
            streaming=True,
            openai_api_key=api_key,
            openai_api_base=provider_config["base_url"]
        )
        
        self.provider = provider
        self.provider_name = provider_config["name"]
        self.model_name = model_name
        
        # ğŸ”§ å°†APIé…ç½®è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œè®©ä»£ç æ‰§è¡Œå·¥å…·ä¹Ÿèƒ½ä½¿ç”¨
        import os
        os.environ["OPENAI_API_KEY"] = api_key
        os.environ["OPENAI_API_BASE"] = provider_config["base_url"]
        os.environ["MODEL_NAME"] = model_name
        print(f"[OK] APIé…ç½®å·²è®¾ç½®: {self.provider_name} - {self.model_name}")
        
        # è·å–å·¥å…·é›†ï¼ˆæ–‡æ¡£åˆ†æ + ä»£ç æ‰§è¡Œï¼‰
        self.tools = get_document_tools() + get_code_execution_tools()
        
        # å®šä¹‰ Agent çš„ Promptï¼ˆç®€åŒ–ç‰ˆï¼Œæ˜ç¡®ä¸‰æ­¥æµç¨‹ï¼‰
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£å¤„ç†åŠ©æ‰‹ã€‚

ä½ çš„ä»»åŠ¡ï¼šæ ¹æ®æ¨¡æ¿æ ¼å¼ç”Ÿæˆæ–°æ–‡æ¡£

ğŸ“‹ æ ‡å‡†å·¥ä½œæµç¨‹ï¼ˆä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œä¸‰æ­¥ï¼‰ï¼š

**ç¬¬1æ­¥ï¼šåˆ†ææ¨¡æ¿** ğŸ“
- è°ƒç”¨å·¥å…·ï¼šanalyze_template_structure(æ¨¡æ¿æ–‡ä»¶è·¯å¾„)
- ç›®çš„ï¼šäº†è§£æ¨¡æ¿ä¸­æœ‰å“ªäº›æ ·å¼ï¼ˆæ ‡é¢˜æ ·å¼ã€æ­£æ–‡æ ·å¼ã€å­—ä½“å¤§å°ç­‰ï¼‰
- è®°ä½åˆ†æç»“æœçš„å…³é”®ä¿¡æ¯

**ç¬¬2æ­¥ï¼šåˆ†æå†…å®¹** ğŸ“„
- è°ƒç”¨å·¥å…·ï¼šanalyze_content_structure(å†…å®¹æ–‡ä»¶è·¯å¾„)
- ç›®çš„ï¼šè¯†åˆ«å†…å®¹ä¸­å“ªäº›æ˜¯æ ‡é¢˜ã€å“ªäº›æ˜¯æ­£æ–‡ã€æœ‰æ— å›¾ç‰‡å’Œè¡¨æ ¼
- è®°ä½åˆ†æç»“æœçš„å…³é”®ä¿¡æ¯

**ç¬¬3æ­¥ï¼šç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ** ğŸš€
- è°ƒç”¨å·¥å…·ï¼šgenerate_and_execute_document_code
- å¿…éœ€å‚æ•°ï¼ˆä»ç”¨æˆ·æŒ‡ä»¤çš„ã€æ–‡ä»¶ä¿¡æ¯ã€‘éƒ¨åˆ†è·å–ï¼‰ï¼š
  * template_path: æ¨¡æ¿æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
  * content_path: å†…å®¹æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
  * output_path: è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
  * template_summary: ç¬¬1æ­¥å¾—åˆ°çš„æ¨¡æ¿åˆ†ææ‘˜è¦ï¼ˆç®€çŸ­æ–‡å­—ï¼Œä¸è¦ä¼ JSONï¼ï¼‰
  * content_summary: ç¬¬2æ­¥å¾—åˆ°çš„å†…å®¹åˆ†ææ‘˜è¦ï¼ˆç®€çŸ­æ–‡å­—ï¼Œä¸è¦ä¼ JSONï¼ï¼‰
- è¿™ä¸ªå·¥å…·ä¼šè‡ªåŠ¨ç”ŸæˆPythonä»£ç å¹¶æ‰§è¡Œï¼Œä½ ä¸éœ€è¦åšå…¶ä»–äº‹æƒ…

âš ï¸ é‡è¦æé†’ï¼š
1. ä¸¥æ ¼æŒ‰ç…§1â†’2â†’3çš„é¡ºåºæ‰§è¡Œï¼Œä¸è¦è·³æ­¥
2. template_summary å’Œ content_summary å¿…é¡»æ˜¯ç®€çŸ­çš„æ–‡å­—æè¿°ï¼Œä¸è¦ä¼ é€’å®Œæ•´çš„JSON
3. æ‰€æœ‰è·¯å¾„éƒ½ä»ç”¨æˆ·æŒ‡ä»¤ä¸­çš„ã€æ–‡ä»¶ä¿¡æ¯ã€‘éƒ¨åˆ†è·å–
4. ç¬¬3æ­¥è°ƒç”¨åï¼Œä»£ç ä¼šè‡ªåŠ¨æ‰§è¡Œï¼Œä¸éœ€è¦ä½ å†åšä»»ä½•å¤„ç†

å°±è¿™ä¹ˆç®€å•ï¼ä¸‰æ­¥èµ°ï¼Œå®Œæˆä»»åŠ¡ã€‚
"""),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # åˆ›å»º Agent
        agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # åˆ›å»º Executorï¼ˆçœŸæ­£æ‰§è¡Œ Agent çš„ç»„ä»¶ï¼‰
        self.executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=True,  # æ‰“å°è¯¦ç»†æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
            handle_parsing_errors=True,
            max_iterations=15,  # å¢åŠ è¿­ä»£æ¬¡æ•°
            return_intermediate_steps=True  # è¿”å›ä¸­é—´æ­¥éª¤
        )
    
    def process(self, file_path: str, instruction: str, progress_callback=None) -> dict:
        """
        å¤„ç†æ–‡æ¡£
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            instruction: ç”¨æˆ·æŒ‡ä»¤
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            if progress_callback:
                progress_callback("ğŸ” åˆ†æç”¨æˆ·éœ€æ±‚...")
            
            # æ„å»ºå®Œæ•´çš„è¾“å…¥
            full_input = f"""
æ–‡ä»¶è·¯å¾„ï¼š{file_path}

ç”¨æˆ·éœ€æ±‚ï¼š{instruction}

è¯·æŒ‰ç…§ç”¨æˆ·éœ€æ±‚å¤„ç†æ–‡æ¡£ï¼Œå¹¶è¿”å›å¤„ç†ç»“æœã€‚
"""
            
            if progress_callback:
                progress_callback("ğŸ¤– å¯åŠ¨ Agent æ‰§è¡Œ...")
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒæ¥æ•è·ä¸­é—´æ­¥éª¤
                if progress_callback:
                    # æ‰§è¡Œ Agent å¹¶æ•è·æ­¥éª¤
                    result = self.executor.invoke({"input": full_input})

                    # åˆ†æä¸­é—´æ­¥éª¤ï¼ˆé˜²å¾¡æ€§è§£æï¼šå¤„ç† tool input ä¸º JSON å­—ç¬¦ä¸²çš„æƒ…å†µï¼‰
                    intermediate_steps = result.get("intermediate_steps", [])
                    for i, (action, observation) in enumerate(intermediate_steps):
                        tool_name = action.tool if hasattr(action, 'tool') else 'unknown'
                        # å°è¯•è§£æ action çš„è¾“å…¥ï¼ˆè‹¥ä¸ºå­—ç¬¦ä¸²ä¸”ä¸º JSONï¼Œåˆ™è§£æä¸ºå¯¹è±¡ï¼‰
                        display_input = None
                        try:
                            if hasattr(action, 'tool_input') and isinstance(action.tool_input, str):
                                try:
                                    display_input = json.loads(action.tool_input)
                                except Exception:
                                    display_input = action.tool_input
                            elif hasattr(action, 'tool_input'):
                                display_input = action.tool_input
                        except Exception:
                            display_input = None

                        if display_input is None:
                            progress_callback(f"[STEP] æ­¥éª¤ {i+1}: è°ƒç”¨å·¥å…· {tool_name}")
                        else:
                            progress_callback(f"[STEP] æ­¥éª¤ {i+1}: è°ƒç”¨å·¥å…· {tool_name} å‚æ•°: {display_input}")
            else:
                result = self.executor.invoke({"input": full_input})
            
            if progress_callback:
                progress_callback("[OK] å¤„ç†å®Œæˆ")
            
            return {
                "success": True,
                "output": result["output"],
                "steps": len(result.get("intermediate_steps", []))
            }
        
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ é”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def process_with_template(
        self, 
        template_path: str, 
        content_path: str, 
        output_format: str,
        instruction: str,
        output_path: str = None,
        progress_callback=None
    ) -> dict:
        """
        ä½¿ç”¨æ¨¡æ¿å¤„ç†æ–‡æ¡£
        
        Args:
            template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
            content_path: å†…å®¹æ–‡ä»¶è·¯å¾„
            output_format: è¾“å‡ºæ ¼å¼
            instruction: å®Œæ•´æŒ‡ä»¤
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            if progress_callback:
                progress_callback("ğŸ” åˆ†ææ¨¡æ¿å’Œå†…å®¹...")
            
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œæ·»åŠ åˆ°æŒ‡ä»¤ä¸­
            if output_path:
                instruction = instruction.replace(
                    "output.docx",
                    output_path
                )
                instruction = instruction.replace(
                    "uploads/output.docx",
                    output_path
                )
            
            # æ‰§è¡Œ Agent
            result = self.executor.invoke({"input": instruction})

            if progress_callback:
                # åˆ†æä¸­é—´æ­¥éª¤ï¼ˆå°è¯•è§£æå­—ç¬¦ä¸²å½¢å¼çš„å·¥å…·å‚æ•°ï¼‰
                intermediate_steps = result.get("intermediate_steps", [])
                for i, (action, observation) in enumerate(intermediate_steps):
                    tool_name = action.tool if hasattr(action, 'tool') else 'unknown'
                    display_input = None
                    try:
                        if hasattr(action, 'tool_input') and isinstance(action.tool_input, str):
                            try:
                                display_input = json.loads(action.tool_input)
                            except Exception:
                                display_input = action.tool_input
                        elif hasattr(action, 'tool_input'):
                            display_input = action.tool_input
                    except Exception:
                        display_input = None

                    if display_input is None:
                        progress_callback(f"[STEP] æ­¥éª¤ {i+1}: è°ƒç”¨å·¥å…· {tool_name}")
                    else:
                        progress_callback(f"[STEP] æ­¥éª¤ {i+1}: è°ƒç”¨å·¥å…· {tool_name} å‚æ•°: {display_input}")
            
            if progress_callback:
                progress_callback("[OK] æ¨¡æ¿å¤„ç†å®Œæˆ")
            
            return {
                "success": True,
                "output": result["output"],
                "steps": len(result.get("intermediate_steps", [])),
                "template": template_path,
                "content": content_path,
                "format": output_format
            }
        
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ é”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
